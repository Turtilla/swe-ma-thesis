{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d222c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "path = '../data/korba_corpus/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca2ba467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_corpus_data(path):\n",
    "    \n",
    "    # retrieving all the xml elements for every 'seg' element\n",
    "    ann_list = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if len(dirs) > 0:\n",
    "            for i, directory in enumerate(tqdm(dirs, desc='Loading files...')):\n",
    "                new_path = os.path.join(path, directory, 'ann_morphosyntax.xml')\n",
    "                tree = ET.parse(new_path)\n",
    "                entry_holder = []\n",
    "                for elem in tree.iter():\n",
    "                    if elem.tag == '{http://www.tei-c.org/ns/1.0}seg':\n",
    "                        if len(entry_holder) > 0:\n",
    "                            ann_list.append(entry_holder)\n",
    "                            entry_holder = []\n",
    "                    else:\n",
    "                        entry_holder.append((elem.attrib, elem.text))\n",
    "                ann_list.append(entry_holder)\n",
    "    \n",
    "    # cleaning up the annotations for every word\n",
    "    new_list = []\n",
    "    for i, elem in enumerate(tqdm(ann_list, desc='Cleaning up annotations...')):\n",
    "        new_elem = {}\n",
    "        for j, element in enumerate(elem):\n",
    "            if 'type' in element[0]:\n",
    "                continue\n",
    "            elif 'name' in element[0]:\n",
    "                # orth is a \"corrected\" spelling version - not relevant in this case\n",
    "                #if element[0]['name'] == 'orth':\n",
    "                    #value = elem[j+1][1]\n",
    "                    #new_elem['orth'] = value\n",
    "\n",
    "                # word form\n",
    "                if element[0]['name'] == 'translit':\n",
    "                    value = elem[j+1][1]\n",
    "                    new_elem['translit'] = value\n",
    "\n",
    "                # lemma\n",
    "                elif element[0]['name'] == 'base':\n",
    "                    value = elem[j+1][1]\n",
    "                    new_elem['base'] = value\n",
    "\n",
    "                # ctag is not a UPOS tag so it is not as relevant\n",
    "                #elif element[0]['name'] == 'ctag':\n",
    "                    #value = elem[j+1][0]['value']\n",
    "                    #new_elem['ctag'] = value\n",
    "\n",
    "                # xpos tag\n",
    "                elif element[0]['name'] == 'interpretation':\n",
    "                    value = elem[j+1][1]\n",
    "                    value = \":\".join(value.split(':')[1:])\n",
    "                    new_elem['interpretation'] = value\n",
    "\n",
    "        new_list.append(new_elem)\n",
    "    \n",
    "    return new_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1685a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_corpus_data(corpus_list, outfile, xpos_outfile):\n",
    "    \n",
    "    data_towrite = []\n",
    "    xpos_towrite = []\n",
    "    for element in corpus_list[1:]:\n",
    "        if len(element) == 0:\n",
    "            data_towrite.append('\\n')\n",
    "            xpos_towrite.append('\\n')\n",
    "        elif len(element) == 3:\n",
    "            data_towrite.append(' '.join([element['translit'], element['base'], element['interpretation']])+'\\n')\n",
    "            xpos_towrite.append(' '.join([element['translit'], element['interpretation']])+'\\n')\n",
    "            \n",
    "    with open(outfile, 'w') as f:\n",
    "        f.writelines(data_towrite)\n",
    "    with open(xpos_outfile, 'w') as f:\n",
    "        f.writelines(xpos_towrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b48544b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files...: 100%|███████████████████████████████████████████████████████████████| 850/850 [01:42<00:00,  8.31it/s]\n",
      "Cleaning up annotations...: 100%|███████████████████████████████████████████| 548695/548695 [00:04<00:00, 127102.65it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus_list = extract_corpus_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b3813f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_corpus_data(corpus_list, '../data/korba_clean.txt', '../data/korba_clean_xpos.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81a3727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
