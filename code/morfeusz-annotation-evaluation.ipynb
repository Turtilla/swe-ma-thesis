{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be2606b9",
   "metadata": {},
   "source": [
    "# MORFEUSZ & CONCRAFT EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3677803",
   "metadata": {},
   "source": [
    "### IMPORTS, VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c688d2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/kawu/concraft-pl\n",
    "# https://github.com/kawu/concraft-pl/tree/master/bindings/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab283a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "sys.path.append('../concraft-pl/bindings/python/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5247dac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from morfeusz2 import Morfeusz\n",
    "from concraft_pl2 import Concraft, Server\n",
    "\n",
    "server = Server(model_path='../concraft-pl/model-SGJP.gz')\n",
    "\n",
    "file = '../data/memoirs_3k_corrected.conllu'\n",
    "\n",
    "test_file = '../data/ud-treebanks/UD_Polish-PDB/pl_pdb-ud-test.conllu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0012aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "morfeusz = Morfeusz(expand_tags=True)\n",
    "concraft = Concraft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9108044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "from preproc_bert import remove_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4643c6d",
   "metadata": {},
   "source": [
    "### FUNCTIONS AND CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "706f3bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OriginalAnnotationsFromConllu:\n",
    "    '''A class intended to process and store the tokens and their respective annotations from the original text. Unlike in \n",
    "    preprocessing with Morefusz, this time we only need to store some kinds of the annotation so that the ConlluFormatter class\n",
    "    can work with it.\n",
    "    \n",
    "    Attributes:\n",
    "        tokens (list[str]): A list of all the tokens (without annotation) in the original data. Every element of the list is a string.\n",
    "        gold_standard (list[str]): A list of all the original annotations (without tokens). Every element is a string.\n",
    "        sentences (list[str]): A list of the original sentences (either truly original, if available, or reconstructed).\n",
    "        simple_sentences_tokenized (list[list[str]]): A list of lists representing the tokenized, unannotated sentences, with no regard\n",
    "        as to whether the tokens were written together or not.\n",
    "        simple_gold_standard_tokenized (list[list[str]]): A list of lists representing the gold standard annotations per sentence, \n",
    "        with no regard as to whether the tokens were written together or not.\n",
    "    '''\n",
    "    def __init__(self, sentences: list, simple_sentences_tokenized: list, simple_gold_standard_tokenized: list):\n",
    "        '''The __init__ method of the class.\n",
    "        Constructs the token and tag lists.\n",
    "        \n",
    "        Args:\n",
    "            sentences (list[str]): A list of the original sentences (either truly original, if available, or reconstructed).\n",
    "            simple_sentences_tokenized (list[list[str]]): A list of lists representing the tokenized, unannotated sentences, with no regard\n",
    "            as to whether the tokens were written together or not.\n",
    "            simple_gold_standard_tokenized (list[list[str]]): A list of lists representing the gold standard annotations per sentence, \n",
    "            with no regard as to whether the tokens were written together or not.\n",
    "        '''\n",
    "        self.sentences = sentences\n",
    "        self.simple_sentences_tokenized = simple_sentences_tokenized\n",
    "        self.simple_gold_standard_tokenized = simple_gold_standard_tokenized\n",
    "        \n",
    "        self.tokens = [x for sentence in self.simple_sentences_tokenized for x in sentence]\n",
    "        self.gold_standard = [x for sentence in self.simple_gold_standard_tokenized for x in sentence]\n",
    "        \n",
    "    def __len__(self):\n",
    "        '''The __len__ magic method of the class.\n",
    "            \n",
    "        Returns:\n",
    "            The length of all the elements in all sentences.\n",
    "        '''\n",
    "        return len(self.tokens)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        '''The __getitem__ magic method of the class.\n",
    "            \n",
    "        Args:\n",
    "            index (int): The index signifying the desired element.\n",
    "            \n",
    "        Returns:\n",
    "            A string representing the combination of the original token and annotation.\n",
    "        '''\n",
    "        token = self.tokens[index]\n",
    "        annotation = self.gold_standard[index]\n",
    "        item = '_'.join([token, annotation])\n",
    "            \n",
    "        return item\n",
    "    \n",
    "    def frequencies(self):\n",
    "        '''A method of the class indended for displaying raw and relative frequencies of word classes in the annotation.\n",
    "        \n",
    "        Returns:\n",
    "            A dataframe representing the POS tag, raw frequency, relative frequency.\n",
    "        '''\n",
    "        freqs = []\n",
    "        for item in list(set(self.gold_standard)):\n",
    "            raw = self.gold_standard.count(item)\n",
    "            relative = raw / len(self.gold_standard)\n",
    "            \n",
    "            freqs.append([item, raw, relative])\n",
    "            \n",
    "        freq_pd = pd.DataFrame(freqs, columns=['POS', 'raw', 'relative']).sort_values('relative', ascending=False).set_index('POS')\n",
    "            \n",
    "        return freq_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a293045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tagger_friendly(tokens_tags):\n",
    "    '''A function allowing for the use of split_tags_and_tokens and remove_ranges on nested lists.\n",
    "    \n",
    "    Arguments:\n",
    "        token_tags (list[list]): A list of lists representing sentences with annotations.\n",
    "        \n",
    "    Returns:\n",
    "        Two separate lists of lists representing sentences and their annotations respectively.'''\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    for element in tokens_tags:\n",
    "        mini_tokens, mini_tags = split_tags_and_tokens(remove_ranges(element))\n",
    "        tokens.append(mini_tokens)\n",
    "        tags.append(mini_tags)\n",
    "        \n",
    "    return tokens, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23fc759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_misparsed(standards, preds, tokens):\n",
    "    new_standards = []\n",
    "    new_preds = []\n",
    "    new_tokens = []\n",
    "    for i, sent in enumerate(standards):\n",
    "        \n",
    "        if len(standards[i]) == len(preds[i]):\n",
    "            new_standards.append(standards[i])\n",
    "            new_preds.append(preds[i])\n",
    "            new_tokens.append(tokens[i])\n",
    "        else:\n",
    "            print(f'Deleted entry number {i} due to a parsing error.')\n",
    "            \n",
    "    return new_standards, new_preds, new_tokens\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6851521",
   "metadata": {},
   "source": [
    "### EXECUTION - MODERN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26db7de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the UD test data\n",
    "test_tokens_upos, sents = extract_conllu_data(test_file, 'upos', sentences=True, combined=True)\n",
    "test_tokens_xpos, _ = extract_conllu_data(test_file, 'xpos', sentences=True, combined=True)\n",
    "test_tokens_lemmas, _ = extract_conllu_data(test_file, 'lemma', sentences=True, combined=True)\n",
    "\n",
    "# transforming it to a tagging-friendly format\n",
    "test_tokens, test_upos = make_tagger_friendly(test_tokens_upos)\n",
    "_, test_xpos = make_tagger_friendly(test_tokens_xpos)\n",
    "_, test_lemmas = make_tagger_friendly(test_tokens_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65a24d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_original = OriginalAnnotationsFromConllu(sents, test_tokens, test_upos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e3bfb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 2215/2215 [00:23<00:00, 94.54it/s]\n"
     ]
    }
   ],
   "source": [
    "test_anns = ConlluFormatter(test_original, morfeusz, concraft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45c2e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xpos_preds, test_forms = test_anns.retrieve_anns('xpos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01ad7a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted entry number 251 due to a parsing error.\n",
      "Deleted entry number 619 due to a parsing error.\n",
      "Deleted entry number 646 due to a parsing error.\n",
      "Deleted entry number 688 due to a parsing error.\n",
      "Deleted entry number 693 due to a parsing error.\n",
      "Deleted entry number 804 due to a parsing error.\n",
      "Deleted entry number 906 due to a parsing error.\n",
      "Deleted entry number 968 due to a parsing error.\n",
      "Deleted entry number 1049 due to a parsing error.\n",
      "Deleted entry number 1127 due to a parsing error.\n",
      "Deleted entry number 1186 due to a parsing error.\n",
      "Deleted entry number 1196 due to a parsing error.\n",
      "Deleted entry number 1296 due to a parsing error.\n",
      "Deleted entry number 1403 due to a parsing error.\n",
      "Deleted entry number 1461 due to a parsing error.\n",
      "Deleted entry number 1495 due to a parsing error.\n",
      "Deleted entry number 1496 due to a parsing error.\n",
      "Deleted entry number 1634 due to a parsing error.\n",
      "Deleted entry number 1681 due to a parsing error.\n",
      "Deleted entry number 1698 due to a parsing error.\n",
      "Deleted entry number 1816 due to a parsing error.\n",
      "Deleted entry number 1872 due to a parsing error.\n",
      "Deleted entry number 1893 due to a parsing error.\n",
      "Deleted entry number 1927 due to a parsing error.\n",
      "Deleted entry number 1979 due to a parsing error.\n",
      "Deleted entry number 2007 due to a parsing error.\n",
      "Deleted entry number 2101 due to a parsing error.\n",
      "Deleted entry number 2132 due to a parsing error.\n",
      "Deleted entry number 2161 due to a parsing error.\n",
      "Deleted entry number 2193 due to a parsing error.\n",
      "Deleted entry number 2204 due to a parsing error.\n",
      "Deleted entry number 2214 due to a parsing error.\n"
     ]
    }
   ],
   "source": [
    "test_xpos, test_xpos_preds, _ = reject_misparsed(test_xpos, test_xpos_preds, test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f96d801c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEASURES:\n",
      "Accuracy: 94.58%\n",
      "Precision (weighted): 95.39%\n",
      "Recall (weighted): 94.58%\n",
      "F1 (weighted): 94.66%\n",
      "Matthew's Correlation Coefficient: 94.37%\n"
     ]
    }
   ],
   "source": [
    "get_measures([x for sentence in test_xpos for x in sentence], [x for sentence in test_xpos_preds for x in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7a3266",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lemma_preds, test_forms = test_anns.retrieve_anns('lemma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86243976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted entry number 251 due to a parsing error.\n",
      "Deleted entry number 619 due to a parsing error.\n",
      "Deleted entry number 646 due to a parsing error.\n",
      "Deleted entry number 688 due to a parsing error.\n",
      "Deleted entry number 693 due to a parsing error.\n",
      "Deleted entry number 804 due to a parsing error.\n",
      "Deleted entry number 881 due to a parsing error.\n",
      "Deleted entry number 906 due to a parsing error.\n",
      "Deleted entry number 968 due to a parsing error.\n",
      "Deleted entry number 1049 due to a parsing error.\n",
      "Deleted entry number 1127 due to a parsing error.\n",
      "Deleted entry number 1186 due to a parsing error.\n",
      "Deleted entry number 1196 due to a parsing error.\n",
      "Deleted entry number 1296 due to a parsing error.\n",
      "Deleted entry number 1403 due to a parsing error.\n",
      "Deleted entry number 1461 due to a parsing error.\n",
      "Deleted entry number 1495 due to a parsing error.\n",
      "Deleted entry number 1496 due to a parsing error.\n",
      "Deleted entry number 1634 due to a parsing error.\n",
      "Deleted entry number 1681 due to a parsing error.\n",
      "Deleted entry number 1698 due to a parsing error.\n",
      "Deleted entry number 1816 due to a parsing error.\n",
      "Deleted entry number 1872 due to a parsing error.\n",
      "Deleted entry number 1893 due to a parsing error.\n",
      "Deleted entry number 1927 due to a parsing error.\n",
      "Deleted entry number 1979 due to a parsing error.\n",
      "Deleted entry number 2007 due to a parsing error.\n",
      "Deleted entry number 2101 due to a parsing error.\n",
      "Deleted entry number 2132 due to a parsing error.\n",
      "Deleted entry number 2161 due to a parsing error.\n",
      "Deleted entry number 2193 due to a parsing error.\n",
      "Deleted entry number 2204 due to a parsing error.\n",
      "Deleted entry number 2214 due to a parsing error.\n"
     ]
    }
   ],
   "source": [
    "test_lemmas, test_lemma_preds, _ = reject_misparsed(test_lemmas, test_lemma_preds, test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb9b9bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.23%\n"
     ]
    }
   ],
   "source": [
    "get_lemma_measures(test_lemmas, test_lemma_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a343b1",
   "metadata": {},
   "source": [
    "### EXECUTION - HISTORICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17bcb2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the test data\n",
    "tokens_upos, sents = extract_conllu_data(file, 'upos', sentences=True, combined=True)\n",
    "tokens_xpos, _ = extract_conllu_data(file, 'xpos', sentences=True, combined=True)\n",
    "tokens_lemmas, _ = extract_conllu_data(file, 'lemma', sentences=True, combined=True)\n",
    "\n",
    "# transforming it to a tagging-friendly format\n",
    "tokens, upos = make_tagger_friendly(tokens_upos)\n",
    "_, xpos = make_tagger_friendly(tokens_xpos)\n",
    "_, lemmas = make_tagger_friendly(tokens_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fa26cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = OriginalAnnotationsFromConllu(sents, tokens, upos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e03e1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 115/115 [00:03<00:00, 38.32it/s]\n"
     ]
    }
   ],
   "source": [
    "anns = ConlluFormatter(original, morfeusz, concraft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2f0f7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "xpos_preds, forms = anns.retrieve_anns('xpos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "485fc211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted entry number 48 due to a parsing error.\n",
      "Deleted entry number 49 due to a parsing error.\n"
     ]
    }
   ],
   "source": [
    "xpos, xpos_preds, new_tokens = reject_misparsed(xpos, xpos_preds, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a201113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xpos = [x for sentence in xpos for x in sentence]\n",
    "xpos_preds = [x for sentence in xpos_preds for x in sentence]\n",
    "new_tokens = [x for sentence in new_tokens for x in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4dde829b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEASURES:\n",
      "Accuracy: 87.85%\n",
      "Precision (weighted): 89.79%\n",
      "Recall (weighted): 87.85%\n",
      "F1 (weighted): 88.17%\n",
      "Matthew's Correlation Coefficient: 87.46%\n"
     ]
    }
   ],
   "source": [
    "get_measures(xpos, xpos_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e52d7bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "xpos_comparison = get_comparison(xpos, xpos_preds, new_tokens)\n",
    "xpos_comparison.to_excel('../data/mistakes/Morfeusz_XPOS_mistakes.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bf5e7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Context</th>\n",
       "      <th>Gold Standard</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dziad</td>\n",
       "      <td>Dziad mój</td>\n",
       "      <td>subst:sg:nom:m1</td>\n",
       "      <td>subst:sg:acc:f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mój</td>\n",
       "      <td>Dziad mój Melchior</td>\n",
       "      <td>adj:sg:nom:m1:pos</td>\n",
       "      <td>adj:sg:nom:m3:pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Melchior</td>\n",
       "      <td>mój Melchior urodzony</td>\n",
       "      <td>subst:sg:nom:m1</td>\n",
       "      <td>subst:sg:nom:m3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>urodzony</td>\n",
       "      <td>Melchior urodzony roku</td>\n",
       "      <td>adj:sg:nom:m1:pos</td>\n",
       "      <td>adj:sg:nom:m3:pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1741</td>\n",
       "      <td>roku 1741 we</td>\n",
       "      <td>adj:sg:gen:m3:pos</td>\n",
       "      <td>dig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>secundo</td>\n",
       "      <td>Julia secundo voto</td>\n",
       "      <td>ign</td>\n",
       "      <td>subst:sg:nom:f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>voto</td>\n",
       "      <td>secundo voto Szołayska</td>\n",
       "      <td>ign</td>\n",
       "      <td>part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>ich</td>\n",
       "      <td>miała ich też</td>\n",
       "      <td>ppron3:pl:acc:m3:ter:akc:npraep</td>\n",
       "      <td>ppron3:pl:acc:m1:ter:akc:npraep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Lesniowic</td>\n",
       "      <td>do Lesniowic przyległe</td>\n",
       "      <td>subst:pl:gen:n:pt</td>\n",
       "      <td>subst:sg:gen:n:ncol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>Mosty</td>\n",
       "      <td>przyległe Mosty .</td>\n",
       "      <td>subst:pl:acc:n:pt</td>\n",
       "      <td>subst:pl:acc:m3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>394 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token                 Context                    Gold Standard  \\\n",
       "0        Dziad               Dziad mój                  subst:sg:nom:m1   \n",
       "1          mój      Dziad mój Melchior                adj:sg:nom:m1:pos   \n",
       "2     Melchior   mój Melchior urodzony                  subst:sg:nom:m1   \n",
       "3     urodzony  Melchior urodzony roku                adj:sg:nom:m1:pos   \n",
       "4         1741            roku 1741 we                adj:sg:gen:m3:pos   \n",
       "..         ...                     ...                              ...   \n",
       "389    secundo      Julia secundo voto                              ign   \n",
       "390       voto  secundo voto Szołayska                              ign   \n",
       "391        ich           miała ich też  ppron3:pl:acc:m3:ter:akc:npraep   \n",
       "392  Lesniowic  do Lesniowic przyległe                subst:pl:gen:n:pt   \n",
       "393      Mosty       przyległe Mosty .                subst:pl:acc:n:pt   \n",
       "\n",
       "                          Prediction  \n",
       "0                     subst:sg:acc:f  \n",
       "1                  adj:sg:nom:m3:pos  \n",
       "2                    subst:sg:nom:m3  \n",
       "3                  adj:sg:nom:m3:pos  \n",
       "4                                dig  \n",
       "..                               ...  \n",
       "389                   subst:sg:nom:f  \n",
       "390                             part  \n",
       "391  ppron3:pl:acc:m1:ter:akc:npraep  \n",
       "392              subst:sg:gen:n:ncol  \n",
       "393                  subst:pl:acc:m3  \n",
       "\n",
       "[394 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xpos_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12bd61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_preds, forms = anns.retrieve_anns('lemma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ac261e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted entry number 48 due to a parsing error.\n",
      "Deleted entry number 49 due to a parsing error.\n"
     ]
    }
   ],
   "source": [
    "lemmas, lemma_preds, new_tokens = reject_misparsed(lemmas, lemma_preds, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78c8911f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.31%\n"
     ]
    }
   ],
   "source": [
    "get_lemma_measures(lemmas, lemma_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91bd3989",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_comparison = get_lemma_comparison(lemmas, lemma_preds, new_tokens)\n",
    "lemma_comparison.to_excel('../data/mistakes/Morfeusz_lemma_mistakes.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "024275eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Context</th>\n",
       "      <th>Gold Standard</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dobrrzyńskiej</td>\n",
       "      <td>ziemi dobrrzyńskiej (</td>\n",
       "      <td>dobrzyńska</td>\n",
       "      <td>dobrrzyńskiej</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p</td>\n",
       "      <td>. p .</td>\n",
       "      <td>p</td>\n",
       "      <td>list_świętego_piotra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wdokumentach</td>\n",
       "      <td>później wdokumentach się</td>\n",
       "      <td>dokument</td>\n",
       "      <td>wdokumentach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pinińskich</td>\n",
       "      <td>z pinińskich właścicieli</td>\n",
       "      <td>Piniński</td>\n",
       "      <td>Pinińskich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adlinencjami</td>\n",
       "      <td>z adlinencjami puszczanki</td>\n",
       "      <td>adlinencja</td>\n",
       "      <td>adlinencjami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>ciepłey</td>\n",
       "      <td>ale ciepłey wdowy</td>\n",
       "      <td>ciepła</td>\n",
       "      <td>ciepłey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>szołayskiego</td>\n",
       "      <td>pana szołayskiego młodzika</td>\n",
       "      <td>Szołayski</td>\n",
       "      <td>Szołayskiego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>procesa</td>\n",
       "      <td>lubiła procesa –</td>\n",
       "      <td>proces</td>\n",
       "      <td>procesa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>lesniowic</td>\n",
       "      <td>do lesniowic przyległe</td>\n",
       "      <td>Lesniowice</td>\n",
       "      <td>Lesniowic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>mosty</td>\n",
       "      <td>przyległe mosty .</td>\n",
       "      <td>Mosty</td>\n",
       "      <td>Most</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Token                     Context Gold Standard  \\\n",
       "0    dobrrzyńskiej       ziemi dobrrzyńskiej (    dobrzyńska   \n",
       "1                p                       . p .             p   \n",
       "2     wdokumentach    później wdokumentach się      dokument   \n",
       "3       pinińskich    z pinińskich właścicieli      Piniński   \n",
       "4     adlinencjami   z adlinencjami puszczanki    adlinencja   \n",
       "..             ...                         ...           ...   \n",
       "147        ciepłey           ale ciepłey wdowy        ciepła   \n",
       "148   szołayskiego  pana szołayskiego młodzika     Szołayski   \n",
       "149        procesa            lubiła procesa –        proces   \n",
       "150      lesniowic      do lesniowic przyległe    Lesniowice   \n",
       "151          mosty           przyległe mosty .         Mosty   \n",
       "\n",
       "               Prediction  \n",
       "0           dobrrzyńskiej  \n",
       "1    list_świętego_piotra  \n",
       "2            wdokumentach  \n",
       "3              Pinińskich  \n",
       "4            adlinencjami  \n",
       "..                    ...  \n",
       "147               ciepłey  \n",
       "148          Szołayskiego  \n",
       "149               procesa  \n",
       "150             Lesniowic  \n",
       "151                  Most  \n",
       "\n",
       "[152 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
